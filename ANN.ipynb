{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>15674932</td>\n",
       "      <td>Okwudilichukwu</td>\n",
       "      <td>668</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>33.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>181449.97</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>15749177</td>\n",
       "      <td>Okwudiliolisa</td>\n",
       "      <td>627</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>49503.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>15694510</td>\n",
       "      <td>Hsueh</td>\n",
       "      <td>678</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>40.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>184866.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>15741417</td>\n",
       "      <td>Kao</td>\n",
       "      <td>581</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>34.0</td>\n",
       "      <td>2</td>\n",
       "      <td>148882.54</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>84560.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>15766172</td>\n",
       "      <td>Chiemenam</td>\n",
       "      <td>716</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>33.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15068.83</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>15771669</td>\n",
       "      <td>Genovese</td>\n",
       "      <td>588</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>36.0</td>\n",
       "      <td>4</td>\n",
       "      <td>131778.58</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>136024.31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>15692819</td>\n",
       "      <td>Ch'ang</td>\n",
       "      <td>593</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>30.0</td>\n",
       "      <td>8</td>\n",
       "      <td>144772.69</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29792.11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>15669611</td>\n",
       "      <td>Chukwuebuka</td>\n",
       "      <td>678</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1</td>\n",
       "      <td>138476.41</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>106851.60</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>15691707</td>\n",
       "      <td>Manna</td>\n",
       "      <td>676</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>43.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>142917.13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>15591721</td>\n",
       "      <td>Cattaneo</td>\n",
       "      <td>583</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>40.0</td>\n",
       "      <td>4</td>\n",
       "      <td>81274.33</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>170843.07</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  CustomerId         Surname  CreditScore Geography  Gender   Age  \\\n",
       "0   0    15674932  Okwudilichukwu          668    France    Male  33.0   \n",
       "1   1    15749177   Okwudiliolisa          627    France    Male  33.0   \n",
       "2   2    15694510           Hsueh          678    France    Male  40.0   \n",
       "3   3    15741417             Kao          581    France    Male  34.0   \n",
       "4   4    15766172       Chiemenam          716     Spain    Male  33.0   \n",
       "5   5    15771669        Genovese          588   Germany    Male  36.0   \n",
       "6   6    15692819          Ch'ang          593    France  Female  30.0   \n",
       "7   7    15669611     Chukwuebuka          678     Spain    Male  37.0   \n",
       "8   8    15691707           Manna          676    France    Male  43.0   \n",
       "9   9    15591721        Cattaneo          583   Germany    Male  40.0   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       3       0.00              2        1.0             0.0   \n",
       "1       1       0.00              2        1.0             1.0   \n",
       "2      10       0.00              2        1.0             0.0   \n",
       "3       2  148882.54              1        1.0             1.0   \n",
       "4       5       0.00              2        1.0             1.0   \n",
       "5       4  131778.58              1        1.0             0.0   \n",
       "6       8  144772.69              1        1.0             0.0   \n",
       "7       1  138476.41              1        1.0             0.0   \n",
       "8       4       0.00              2        1.0             0.0   \n",
       "9       4   81274.33              1        1.0             1.0   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        181449.97       0  \n",
       "1         49503.50       0  \n",
       "2        184866.69       0  \n",
       "3         84560.88       0  \n",
       "4         15068.83       0  \n",
       "5        136024.31       1  \n",
       "6         29792.11       0  \n",
       "7        106851.60       0  \n",
       "8        142917.13       0  \n",
       "9        170843.07       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 165034 entries, 0 to 165033\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count   Dtype  \n",
      "---  ------           --------------   -----  \n",
      " 0   id               165034 non-null  int64  \n",
      " 1   CustomerId       165034 non-null  int64  \n",
      " 2   Surname          165034 non-null  object \n",
      " 3   CreditScore      165034 non-null  int64  \n",
      " 4   Geography        165034 non-null  object \n",
      " 5   Gender           165034 non-null  object \n",
      " 6   Age              165034 non-null  float64\n",
      " 7   Tenure           165034 non-null  int64  \n",
      " 8   Balance          165034 non-null  float64\n",
      " 9   NumOfProducts    165034 non-null  int64  \n",
      " 10  HasCrCard        165034 non-null  float64\n",
      " 11  IsActiveMember   165034 non-null  float64\n",
      " 12  EstimatedSalary  165034 non-null  float64\n",
      " 13  Exited           165034 non-null  int64  \n",
      "dtypes: float64(5), int64(6), object(3)\n",
      "memory usage: 17.6+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>668</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>33.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>181449.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>627</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>49503.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>678</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>40.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>184866.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>581</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>34.0</td>\n",
       "      <td>2</td>\n",
       "      <td>148882.54</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>84560.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>716</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>33.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15068.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>588</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>36.0</td>\n",
       "      <td>4</td>\n",
       "      <td>131778.58</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>136024.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>593</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>30.0</td>\n",
       "      <td>8</td>\n",
       "      <td>144772.69</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29792.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>678</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1</td>\n",
       "      <td>138476.41</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>106851.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>676</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>43.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>142917.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>583</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>40.0</td>\n",
       "      <td>4</td>\n",
       "      <td>81274.33</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>170843.07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore Geography  Gender   Age  Tenure    Balance  NumOfProducts  \\\n",
       "0          668    France    Male  33.0       3       0.00              2   \n",
       "1          627    France    Male  33.0       1       0.00              2   \n",
       "2          678    France    Male  40.0      10       0.00              2   \n",
       "3          581    France    Male  34.0       2  148882.54              1   \n",
       "4          716     Spain    Male  33.0       5       0.00              2   \n",
       "5          588   Germany    Male  36.0       4  131778.58              1   \n",
       "6          593    France  Female  30.0       8  144772.69              1   \n",
       "7          678     Spain    Male  37.0       1  138476.41              1   \n",
       "8          676    France    Male  43.0       4       0.00              2   \n",
       "9          583   Germany    Male  40.0       4   81274.33              1   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  \n",
       "0        1.0             0.0        181449.97  \n",
       "1        1.0             1.0         49503.50  \n",
       "2        1.0             0.0        184866.69  \n",
       "3        1.0             1.0         84560.88  \n",
       "4        1.0             1.0         15068.83  \n",
       "5        1.0             0.0        136024.31  \n",
       "6        1.0             0.0         29792.11  \n",
       "7        1.0             0.0        106851.60  \n",
       "8        1.0             0.0        142917.13  \n",
       "9        1.0             1.0        170843.07  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = train_df[\"Exited\"]\n",
    "train_df = train_df.drop(['Exited', 'CustomerId', 'Surname', 'id'], axis=1)\n",
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Geography', 'Gender']\n"
     ]
    }
   ],
   "source": [
    "categorical_fearures = [feature for feature in train_df.columns if train_df[feature].dtype == 'object']\n",
    "print(categorical_fearures)\n",
    "oh = LabelEncoder()\n",
    "for i in categorical_fearures:\n",
    "    train_df[i] = oh.fit_transform(train_df[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>668</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>33.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>181449.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>627</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>49503.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>678</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>40.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>184866.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>581</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>34.0</td>\n",
       "      <td>2</td>\n",
       "      <td>148882.54</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>84560.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>716</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>33.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15068.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>588</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>36.0</td>\n",
       "      <td>4</td>\n",
       "      <td>131778.58</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>136024.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>593</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>8</td>\n",
       "      <td>144772.69</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29792.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>678</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1</td>\n",
       "      <td>138476.41</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>106851.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>676</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>43.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>142917.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>583</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>40.0</td>\n",
       "      <td>4</td>\n",
       "      <td>81274.33</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>170843.07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore  Geography  Gender   Age  Tenure    Balance  NumOfProducts  \\\n",
       "0          668          0       1  33.0       3       0.00              2   \n",
       "1          627          0       1  33.0       1       0.00              2   \n",
       "2          678          0       1  40.0      10       0.00              2   \n",
       "3          581          0       1  34.0       2  148882.54              1   \n",
       "4          716          2       1  33.0       5       0.00              2   \n",
       "5          588          1       1  36.0       4  131778.58              1   \n",
       "6          593          0       0  30.0       8  144772.69              1   \n",
       "7          678          2       1  37.0       1  138476.41              1   \n",
       "8          676          0       1  43.0       4       0.00              2   \n",
       "9          583          1       1  40.0       4   81274.33              1   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  \n",
       "0        1.0             0.0        181449.97  \n",
       "1        1.0             1.0         49503.50  \n",
       "2        1.0             0.0        184866.69  \n",
       "3        1.0             1.0         84560.88  \n",
       "4        1.0             1.0         15068.83  \n",
       "5        1.0             0.0        136024.31  \n",
       "6        1.0             0.0         29792.11  \n",
       "7        1.0             0.0        106851.60  \n",
       "8        1.0             0.0        142917.13  \n",
       "9        1.0             1.0        170843.07  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(train_df, target, test_size=0.2, random_state=42)\n",
    "\n",
    "x_train = StandardScaler().fit_transform(x_train)\n",
    "x_test = StandardScaler().fit_transform(x_test)\n",
    "# y_train = StandardScaler().fit_transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8846/8846 [==============================] - 13s 1ms/step - loss: 0.4451 - accuracy: 0.8049 - val_loss: 0.3854 - val_accuracy: 0.8371\n",
      "Epoch 2/100\n",
      "8846/8846 [==============================] - 12s 1ms/step - loss: 0.3718 - accuracy: 0.8411 - val_loss: 0.3571 - val_accuracy: 0.8473\n",
      "Epoch 3/100\n",
      "8846/8846 [==============================] - 12s 1ms/step - loss: 0.3498 - accuracy: 0.8497 - val_loss: 0.3429 - val_accuracy: 0.8539\n",
      "Epoch 4/100\n",
      "8846/8846 [==============================] - 12s 1ms/step - loss: 0.3404 - accuracy: 0.8542 - val_loss: 0.3379 - val_accuracy: 0.8572\n",
      "Epoch 5/100\n",
      "8846/8846 [==============================] - 12s 1ms/step - loss: 0.3363 - accuracy: 0.8572 - val_loss: 0.3350 - val_accuracy: 0.8583\n",
      "Epoch 6/100\n",
      "8846/8846 [==============================] - 12s 1ms/step - loss: 0.3342 - accuracy: 0.8580 - val_loss: 0.3332 - val_accuracy: 0.8604\n",
      "Epoch 7/100\n",
      "8846/8846 [==============================] - 12s 1ms/step - loss: 0.3328 - accuracy: 0.8603 - val_loss: 0.3319 - val_accuracy: 0.8625\n",
      "Epoch 8/100\n",
      "8846/8846 [==============================] - 11s 1ms/step - loss: 0.3317 - accuracy: 0.8606 - val_loss: 0.3308 - val_accuracy: 0.8627\n",
      "Epoch 9/100\n",
      "8846/8846 [==============================] - 12s 1ms/step - loss: 0.3310 - accuracy: 0.8615 - val_loss: 0.3306 - val_accuracy: 0.8633\n",
      "Epoch 10/100\n",
      "8846/8846 [==============================] - 12s 1ms/step - loss: 0.3305 - accuracy: 0.8614 - val_loss: 0.3308 - val_accuracy: 0.8632\n",
      "Epoch 11/100\n",
      "8846/8846 [==============================] - 12s 1ms/step - loss: 0.3301 - accuracy: 0.8616 - val_loss: 0.3298 - val_accuracy: 0.8642\n",
      "Epoch 12/100\n",
      "8846/8846 [==============================] - 12s 1ms/step - loss: 0.3298 - accuracy: 0.8621 - val_loss: 0.3293 - val_accuracy: 0.8638\n",
      "Epoch 13/100\n",
      "8846/8846 [==============================] - 11s 1ms/step - loss: 0.3296 - accuracy: 0.8621 - val_loss: 0.3295 - val_accuracy: 0.8636\n",
      "Epoch 14/100\n",
      "8846/8846 [==============================] - 12s 1ms/step - loss: 0.3295 - accuracy: 0.8628 - val_loss: 0.3298 - val_accuracy: 0.8632\n",
      "Epoch 15/100\n",
      "8846/8846 [==============================] - 12s 1ms/step - loss: 0.3292 - accuracy: 0.8622 - val_loss: 0.3292 - val_accuracy: 0.8635\n",
      "Epoch 16/100\n",
      "8846/8846 [==============================] - 12s 1ms/step - loss: 0.3291 - accuracy: 0.8630 - val_loss: 0.3291 - val_accuracy: 0.8631\n",
      "Epoch 17/100\n",
      "8846/8846 [==============================] - 12s 1ms/step - loss: 0.3289 - accuracy: 0.8628 - val_loss: 0.3296 - val_accuracy: 0.8634\n",
      "Epoch 18/100\n",
      "8846/8846 [==============================] - 13s 2ms/step - loss: 0.3289 - accuracy: 0.8625 - val_loss: 0.3300 - val_accuracy: 0.8627\n",
      "Epoch 19/100\n",
      "8846/8846 [==============================] - 14s 2ms/step - loss: 0.3288 - accuracy: 0.8626 - val_loss: 0.3285 - val_accuracy: 0.8635\n",
      "Epoch 20/100\n",
      "8846/8846 [==============================] - 12s 1ms/step - loss: 0.3287 - accuracy: 0.8624 - val_loss: 0.3287 - val_accuracy: 0.8641\n",
      "Epoch 21/100\n",
      "8846/8846 [==============================] - 13s 1ms/step - loss: 0.3286 - accuracy: 0.8628 - val_loss: 0.3285 - val_accuracy: 0.8644\n",
      "Epoch 22/100\n",
      "8846/8846 [==============================] - 12s 1ms/step - loss: 0.3284 - accuracy: 0.8626 - val_loss: 0.3290 - val_accuracy: 0.8635\n",
      "Epoch 23/100\n",
      "8846/8846 [==============================] - 14s 2ms/step - loss: 0.3284 - accuracy: 0.8626 - val_loss: 0.3283 - val_accuracy: 0.8635\n",
      "Epoch 24/100\n",
      "8846/8846 [==============================] - 15s 2ms/step - loss: 0.3283 - accuracy: 0.8620 - val_loss: 0.3282 - val_accuracy: 0.8643\n",
      "Epoch 25/100\n",
      "8846/8846 [==============================] - 13s 1ms/step - loss: 0.3282 - accuracy: 0.8626 - val_loss: 0.3281 - val_accuracy: 0.8636\n",
      "Epoch 26/100\n",
      "8846/8846 [==============================] - 12s 1ms/step - loss: 0.3282 - accuracy: 0.8629 - val_loss: 0.3278 - val_accuracy: 0.8641\n",
      "Epoch 27/100\n",
      "8846/8846 [==============================] - 12s 1ms/step - loss: 0.3281 - accuracy: 0.8626 - val_loss: 0.3278 - val_accuracy: 0.8644\n",
      "Epoch 28/100\n",
      "8846/8846 [==============================] - 12s 1ms/step - loss: 0.3279 - accuracy: 0.8630 - val_loss: 0.3281 - val_accuracy: 0.8638\n",
      "Epoch 29/100\n",
      "8846/8846 [==============================] - 15s 2ms/step - loss: 0.3278 - accuracy: 0.8628 - val_loss: 0.3276 - val_accuracy: 0.8640\n",
      "Epoch 30/100\n",
      "8846/8846 [==============================] - 12s 1ms/step - loss: 0.3277 - accuracy: 0.8629 - val_loss: 0.3278 - val_accuracy: 0.8644\n",
      "Epoch 31/100\n",
      "8846/8846 [==============================] - 15s 2ms/step - loss: 0.3275 - accuracy: 0.8628 - val_loss: 0.3281 - val_accuracy: 0.8643\n",
      "Epoch 32/100\n",
      "8846/8846 [==============================] - 15s 2ms/step - loss: 0.3274 - accuracy: 0.8632 - val_loss: 0.3276 - val_accuracy: 0.8643\n",
      "Epoch 33/100\n",
      "8846/8846 [==============================] - 15s 2ms/step - loss: 0.3273 - accuracy: 0.8630 - val_loss: 0.3279 - val_accuracy: 0.8635\n",
      "Epoch 34/100\n",
      "8846/8846 [==============================] - 15s 2ms/step - loss: 0.3271 - accuracy: 0.8631 - val_loss: 0.3276 - val_accuracy: 0.8637\n",
      "Epoch 35/100\n",
      "8846/8846 [==============================] - 12s 1ms/step - loss: 0.3270 - accuracy: 0.8636 - val_loss: 0.3270 - val_accuracy: 0.8636\n",
      "Epoch 36/100\n",
      "8846/8846 [==============================] - 13s 1ms/step - loss: 0.3270 - accuracy: 0.8630 - val_loss: 0.3271 - val_accuracy: 0.8640\n",
      "Epoch 37/100\n",
      "8846/8846 [==============================] - 15s 2ms/step - loss: 0.3269 - accuracy: 0.8634 - val_loss: 0.3267 - val_accuracy: 0.8644\n",
      "Epoch 38/100\n",
      "8846/8846 [==============================] - 15s 2ms/step - loss: 0.3269 - accuracy: 0.8632 - val_loss: 0.3268 - val_accuracy: 0.8640\n",
      "Epoch 39/100\n",
      "8846/8846 [==============================] - 15s 2ms/step - loss: 0.3266 - accuracy: 0.8633 - val_loss: 0.3269 - val_accuracy: 0.8636\n",
      "Epoch 40/100\n",
      "8846/8846 [==============================] - 12s 1ms/step - loss: 0.3267 - accuracy: 0.8632 - val_loss: 0.3270 - val_accuracy: 0.8642\n",
      "Epoch 41/100\n",
      "8846/8846 [==============================] - 12s 1ms/step - loss: 0.3268 - accuracy: 0.8633 - val_loss: 0.3268 - val_accuracy: 0.8637\n",
      "Epoch 42/100\n",
      "8846/8846 [==============================] - 12s 1ms/step - loss: 0.3266 - accuracy: 0.8635 - val_loss: 0.3269 - val_accuracy: 0.8637\n",
      "Epoch 43/100\n",
      "8846/8846 [==============================] - 12s 1ms/step - loss: 0.3266 - accuracy: 0.8633 - val_loss: 0.3267 - val_accuracy: 0.8638\n",
      "Epoch 44/100\n",
      "8846/8846 [==============================] - 21s 2ms/step - loss: 0.3265 - accuracy: 0.8634 - val_loss: 0.3274 - val_accuracy: 0.8641\n",
      "Epoch 45/100\n",
      "8846/8846 [==============================] - 15s 2ms/step - loss: 0.3266 - accuracy: 0.8633 - val_loss: 0.3268 - val_accuracy: 0.8642\n",
      "Epoch 46/100\n",
      "8846/8846 [==============================] - 13s 1ms/step - loss: 0.3265 - accuracy: 0.8635 - val_loss: 0.3265 - val_accuracy: 0.8635\n",
      "Epoch 47/100\n",
      "8846/8846 [==============================] - 12s 1ms/step - loss: 0.3266 - accuracy: 0.8634 - val_loss: 0.3267 - val_accuracy: 0.8643\n",
      "Epoch 48/100\n",
      "8846/8846 [==============================] - 12s 1ms/step - loss: 0.3265 - accuracy: 0.8636 - val_loss: 0.3270 - val_accuracy: 0.8641\n",
      "Epoch 49/100\n",
      "8846/8846 [==============================] - 12s 1ms/step - loss: 0.3264 - accuracy: 0.8635 - val_loss: 0.3270 - val_accuracy: 0.8645\n",
      "Epoch 50/100\n",
      "8846/8846 [==============================] - 12s 1ms/step - loss: 0.3265 - accuracy: 0.8632 - val_loss: 0.3267 - val_accuracy: 0.8646\n",
      "Epoch 51/100\n",
      "8846/8846 [==============================] - 12s 1ms/step - loss: 0.3263 - accuracy: 0.8632 - val_loss: 0.3264 - val_accuracy: 0.8640\n",
      "Epoch 52/100\n",
      "8846/8846 [==============================] - 12s 1ms/step - loss: 0.3263 - accuracy: 0.8634 - val_loss: 0.3269 - val_accuracy: 0.8642\n",
      "Epoch 53/100\n",
      "8846/8846 [==============================] - 12s 1ms/step - loss: 0.3264 - accuracy: 0.8634 - val_loss: 0.3264 - val_accuracy: 0.8643\n",
      "Epoch 54/100\n",
      "8846/8846 [==============================] - 12s 1ms/step - loss: 0.3264 - accuracy: 0.8635 - val_loss: 0.3265 - val_accuracy: 0.8644\n",
      "Epoch 55/100\n",
      "8846/8846 [==============================] - 12s 1ms/step - loss: 0.3263 - accuracy: 0.8640 - val_loss: 0.3267 - val_accuracy: 0.8647\n",
      "Epoch 56/100\n",
      "8846/8846 [==============================] - 12s 1ms/step - loss: 0.3263 - accuracy: 0.8632 - val_loss: 0.3266 - val_accuracy: 0.8636\n",
      "Epoch 57/100\n",
      "8846/8846 [==============================] - 12s 1ms/step - loss: 0.3263 - accuracy: 0.8632 - val_loss: 0.3267 - val_accuracy: 0.8646\n",
      "Epoch 58/100\n",
      "8846/8846 [==============================] - 12s 1ms/step - loss: 0.3263 - accuracy: 0.8635 - val_loss: 0.3267 - val_accuracy: 0.8644\n",
      "Epoch 59/100\n",
      "8846/8846 [==============================] - 22s 2ms/step - loss: 0.3262 - accuracy: 0.8629 - val_loss: 0.3268 - val_accuracy: 0.8640\n",
      "Epoch 60/100\n",
      "8846/8846 [==============================] - 15s 2ms/step - loss: 0.3262 - accuracy: 0.8637 - val_loss: 0.3262 - val_accuracy: 0.8642\n",
      "Epoch 61/100\n",
      "8846/8846 [==============================] - 13s 2ms/step - loss: 0.3263 - accuracy: 0.8634 - val_loss: 0.3265 - val_accuracy: 0.8640\n",
      "Epoch 62/100\n",
      "8846/8846 [==============================] - 14s 2ms/step - loss: 0.3262 - accuracy: 0.8634 - val_loss: 0.3265 - val_accuracy: 0.8642\n",
      "Epoch 63/100\n",
      "8846/8846 [==============================] - 12s 1ms/step - loss: 0.3263 - accuracy: 0.8634 - val_loss: 0.3266 - val_accuracy: 0.8639\n",
      "Epoch 64/100\n",
      "8846/8846 [==============================] - 12s 1ms/step - loss: 0.3262 - accuracy: 0.8635 - val_loss: 0.3265 - val_accuracy: 0.8642\n",
      "Epoch 65/100\n",
      "8846/8846 [==============================] - 12s 1ms/step - loss: 0.3263 - accuracy: 0.8634 - val_loss: 0.3265 - val_accuracy: 0.8638\n",
      "Epoch 66/100\n",
      "8846/8846 [==============================] - 12s 1ms/step - loss: 0.3261 - accuracy: 0.8635 - val_loss: 0.3271 - val_accuracy: 0.8640\n",
      "Epoch 67/100\n",
      "8846/8846 [==============================] - 14s 2ms/step - loss: 0.3262 - accuracy: 0.8633 - val_loss: 0.3264 - val_accuracy: 0.8642\n",
      "Epoch 68/100\n",
      "8846/8846 [==============================] - 19s 2ms/step - loss: 0.3261 - accuracy: 0.8631 - val_loss: 0.3267 - val_accuracy: 0.8635\n",
      "Epoch 69/100\n",
      "8846/8846 [==============================] - 12s 1ms/step - loss: 0.3261 - accuracy: 0.8630 - val_loss: 0.3268 - val_accuracy: 0.8645\n",
      "Epoch 70/100\n",
      "8846/8846 [==============================] - 13s 1ms/step - loss: 0.3261 - accuracy: 0.8642 - val_loss: 0.3264 - val_accuracy: 0.8652\n",
      "Epoch 71/100\n",
      "8846/8846 [==============================] - 15s 2ms/step - loss: 0.3261 - accuracy: 0.8633 - val_loss: 0.3264 - val_accuracy: 0.8639\n",
      "Epoch 72/100\n",
      "8846/8846 [==============================] - 15s 2ms/step - loss: 0.3261 - accuracy: 0.8636 - val_loss: 0.3265 - val_accuracy: 0.8643\n",
      "Epoch 73/100\n",
      "8846/8846 [==============================] - 13s 1ms/step - loss: 0.3261 - accuracy: 0.8634 - val_loss: 0.3266 - val_accuracy: 0.8633\n",
      "Epoch 74/100\n",
      "8846/8846 [==============================] - 12s 1ms/step - loss: 0.3261 - accuracy: 0.8636 - val_loss: 0.3266 - val_accuracy: 0.8641\n",
      "Epoch 75/100\n",
      "8846/8846 [==============================] - 12s 1ms/step - loss: 0.3261 - accuracy: 0.8636 - val_loss: 0.3265 - val_accuracy: 0.8645\n",
      "Epoch 76/100\n",
      "8846/8846 [==============================] - 11s 1ms/step - loss: 0.3261 - accuracy: 0.8641 - val_loss: 0.3264 - val_accuracy: 0.8648\n",
      "Epoch 77/100\n",
      "8846/8846 [==============================] - 12s 1ms/step - loss: 0.3260 - accuracy: 0.8636 - val_loss: 0.3264 - val_accuracy: 0.8644\n",
      "Epoch 78/100\n",
      "8846/8846 [==============================] - 12s 1ms/step - loss: 0.3261 - accuracy: 0.8640 - val_loss: 0.3265 - val_accuracy: 0.8639\n",
      "Epoch 79/100\n",
      "8846/8846 [==============================] - 12s 1ms/step - loss: 0.3261 - accuracy: 0.8632 - val_loss: 0.3278 - val_accuracy: 0.8643\n",
      "Epoch 80/100\n",
      "8846/8846 [==============================] - 15s 2ms/step - loss: 0.3262 - accuracy: 0.8630 - val_loss: 0.3263 - val_accuracy: 0.8640\n",
      "Epoch 81/100\n",
      "8846/8846 [==============================] - 16s 2ms/step - loss: 0.3260 - accuracy: 0.8631 - val_loss: 0.3263 - val_accuracy: 0.8649\n",
      "Epoch 82/100\n",
      "8846/8846 [==============================] - 14s 2ms/step - loss: 0.3261 - accuracy: 0.8631 - val_loss: 0.3267 - val_accuracy: 0.8646\n",
      "Epoch 83/100\n",
      "8846/8846 [==============================] - 12s 1ms/step - loss: 0.3260 - accuracy: 0.8640 - val_loss: 0.3262 - val_accuracy: 0.8644\n",
      "Epoch 84/100\n",
      "8846/8846 [==============================] - 12s 1ms/step - loss: 0.3260 - accuracy: 0.8636 - val_loss: 0.3264 - val_accuracy: 0.8642\n",
      "Epoch 85/100\n",
      "8846/8846 [==============================] - 12s 1ms/step - loss: 0.3260 - accuracy: 0.8634 - val_loss: 0.3261 - val_accuracy: 0.8645\n",
      "Epoch 86/100\n",
      "8846/8846 [==============================] - 12s 1ms/step - loss: 0.3260 - accuracy: 0.8637 - val_loss: 0.3266 - val_accuracy: 0.8640\n",
      "Epoch 87/100\n",
      "8846/8846 [==============================] - 12s 1ms/step - loss: 0.3261 - accuracy: 0.8631 - val_loss: 0.3261 - val_accuracy: 0.8648\n",
      "Epoch 88/100\n",
      "8846/8846 [==============================] - 12s 1ms/step - loss: 0.3260 - accuracy: 0.8640 - val_loss: 0.3262 - val_accuracy: 0.8644\n",
      "Epoch 89/100\n",
      "8846/8846 [==============================] - 14s 2ms/step - loss: 0.3260 - accuracy: 0.8637 - val_loss: 0.3265 - val_accuracy: 0.8645\n",
      "Epoch 90/100\n",
      "8846/8846 [==============================] - 16s 2ms/step - loss: 0.3259 - accuracy: 0.8639 - val_loss: 0.3262 - val_accuracy: 0.8647\n",
      "Epoch 91/100\n",
      "8846/8846 [==============================] - 16s 2ms/step - loss: 0.3261 - accuracy: 0.8633 - val_loss: 0.3261 - val_accuracy: 0.8645\n",
      "Epoch 92/100\n",
      "8846/8846 [==============================] - 16s 2ms/step - loss: 0.3260 - accuracy: 0.8629 - val_loss: 0.3264 - val_accuracy: 0.8637\n",
      "Epoch 93/100\n",
      "8846/8846 [==============================] - 16s 2ms/step - loss: 0.3260 - accuracy: 0.8640 - val_loss: 0.3263 - val_accuracy: 0.8643\n",
      "Epoch 94/100\n",
      "8846/8846 [==============================] - 16s 2ms/step - loss: 0.3260 - accuracy: 0.8634 - val_loss: 0.3262 - val_accuracy: 0.8651\n",
      "Epoch 95/100\n",
      "8846/8846 [==============================] - 16s 2ms/step - loss: 0.3260 - accuracy: 0.8635 - val_loss: 0.3261 - val_accuracy: 0.8643\n",
      "Epoch 96/100\n",
      "8846/8846 [==============================] - 16s 2ms/step - loss: 0.3259 - accuracy: 0.8631 - val_loss: 0.3259 - val_accuracy: 0.8649\n",
      "Epoch 97/100\n",
      "8846/8846 [==============================] - 16s 2ms/step - loss: 0.3260 - accuracy: 0.8639 - val_loss: 0.3263 - val_accuracy: 0.8644\n",
      "Epoch 98/100\n",
      "8846/8846 [==============================] - 16s 2ms/step - loss: 0.3260 - accuracy: 0.8630 - val_loss: 0.3263 - val_accuracy: 0.8649\n",
      "Epoch 99/100\n",
      "8846/8846 [==============================] - 16s 2ms/step - loss: 0.3260 - accuracy: 0.8634 - val_loss: 0.3268 - val_accuracy: 0.8641\n",
      "Epoch 100/100\n",
      "8846/8846 [==============================] - 16s 2ms/step - loss: 0.3259 - accuracy: 0.8639 - val_loss: 0.3262 - val_accuracy: 0.8650\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LeakyReLU, PReLU, ELU, Dropout\n",
    "\n",
    "layer = Sequential()\n",
    "layer.add(Dense(\n",
    "    units=6,                          # Number of neurons in this dense layer.\n",
    "    kernel_initializer='he_uniform',  # Initialization method for the weights, 'he_uniform' is good for ReLU activation to avoid vanishing gradients.\n",
    "    activation='relu',                # Activation function for the layer, ReLU introduces non-linearity and helps with learning complex patterns.\n",
    "    input_dim=10                       # The number of features in the input data, used only in the first layer to define the input shape.\n",
    "))\n",
    "\n",
    "layer.add(Dense(units=6, kernel_initializer='he_uniform', activation='relu'))\n",
    "layer.add(Dense(units=1, kernel_initializer='glorot_uniform', activation='sigmoid'))\n",
    "layer.compile(optimizer='Adamax', loss='binary_crossentropy', metrics=['accuracy'])   # prefer using binary_crossentropy for problems with output 0 or 1 and categorical_crossentropy for multiple classes.\n",
    "\n",
    "model = layer.fit(x_train, y_train, validation_split=0.33, batch_size=10, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1032/1032 [==============================] - 1s 730us/step\n",
      "0.8653012997243009\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = layer.predict(x_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
